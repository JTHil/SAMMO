{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Load from parent directory if not installed\n",
    "import importlib\n",
    "import os\n",
    "\n",
    "if not importlib.util.find_spec(\"sammo\"):\n",
    "    import sys\n",
    "\n",
    "    sys.path.append(\"../\")\n",
    "os.environ[\"CACHE_FILE\"] = \"cache/chaining_prompts.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Using components to write metaprompts\n",
    "\n",
    "In this tutorial, we'll visit a few more advanced concepts for building metaprompts with `SAMMO`. \n",
    "\n",
    "As mentioned before, metaprompts are essentially call graphs that are evaluated lazily with `.run*` methods. What they offer is a way to tell `SAMMO` which things depend on each other which in turns enables efficient scheduling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# %load _init.py\n",
    "import pathlib\n",
    "import sammo\n",
    "from sammo.runners import OpenAIChat\n",
    "from sammo.base import Template\n",
    "from sammo.components import Output, GenerateText, ForEach, Union\n",
    "from sammo.extractors import ExtractRegex\n",
    "\n",
    "API_CONFIG_FILE = pathlib.Path().cwd().parent / \"config\" / \"personal.openai\"\n",
    "API_CONFIG = \"\"\n",
    "if API_CONFIG_FILE.exists():\n",
    "    API_CONFIG = API_CONFIG_FILE\n",
    "if not API_CONFIG:\n",
    "    raise ValueError('Please set API_CONFIG to {\"api_key\": \"YOUR_KEY\"}')\n",
    "\n",
    "_ = sammo.setup_logger(\"WARNING\")  # we're only interested in warnings for now\n",
    "\n",
    "runner = OpenAIChat(\n",
    "    model_id=\"gpt-3.5-turbo-16k\",\n",
    "    api_config=API_CONFIG,\n",
    "    cache=CACHE_FILE,\n",
    "    timeout=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Passing on chat history\n",
    "\n",
    "With newer chat-based LLMs, we might want to construct metaprompts that build on the chat history from previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------------------------------------------------+\n",
      "| input   | output                                                      |\n",
      "+=========+=============================================================+\n",
      "| None    | Ah, thy favorite animal, the horse, doth possess a beauty   |\n",
      "|         | unmatched by any other. With flowing mane and fiery spirit, |\n",
      "|         | it doth gallop upon the fields, a symbol of freedom and     |\n",
      "|         | untamed might.                                              |\n",
      "+---------+-------------------------------------------------------------+\n",
      "Constants: None\n",
      "+---------+--------------------------------------------------------------+\n",
      "| input   | output                                                       |\n",
      "+=========+==============================================================+\n",
      "| None    | In fields of green, the horse doth roam, Its noble spirit, a |\n",
      "|         | beauty to behold. With flowing mane and hooves that pound,   |\n",
      "|         | It gallops free, a sight profound. A symbol of strength,     |\n",
      "|         | untamed and wild, In its presence, my heart is beguiled. Oh, |\n",
      "|         | horse, majestic creature of grace, Forever shall thou hold a |\n",
      "|         | special place.                                               |\n",
      "+---------+--------------------------------------------------------------+\n",
      "Constants: None\n"
     ]
    }
   ],
   "source": [
    "first = GenerateText(\n",
    "    \"Hello! My name is Peter and I like horses.\",\n",
    "    system_prompt=\"Talk like Shakespeare.\",\n",
    ")\n",
    "\n",
    "second = GenerateText(\"Write two sentences about my favorite animal.\", history=first)\n",
    "print(Output(second).run(runner))\n",
    "\n",
    "third = GenerateText(\"Make it a short poem.\", history=second)\n",
    "print(Output(third).run(runner))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Iterating over items\n",
    "There are two main ways of iterating over sequences in `SAMMO`:\n",
    "\n",
    "1. Sequence is known before prompt execution:\n",
    "   1. Automatic iteration via `.run_on_datatable()` or `.run_on_dicts()` as we have seen in the quickstart example. This is recommended to annotate larger data in input-output pairs.\n",
    "   2. Manual iteration via Python list and loop operators.\n",
    "2. Sequence is the result of a prompt execution: Here, `SAMMO`provides the `ForEach` that is called lazily.\n",
    "\n",
    "We now demonstrate the two bottom methods after loading our environment:\n",
    "\n",
    "### Known sequence: Manual iteration via Python \n",
    "\n",
    "A common use case for this is when we want to repeat certain operations for a known number of times, e.g., sample LLM responses *N* times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+---------+-----------------------------------------------------+\n",
       "| input   | output                                              |\n",
       "+=========+=====================================================+\n",
       "| None    | ['Mango', 'Mango', 'Mango', 'Pomegranate', 'Mango'] |\n",
       "+---------+-----------------------------------------------------+\n",
       "Constants: None"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 5\n",
    "fruits = [\n",
    "    GenerateText(\"Generate the name of 1 fruit.\", randomness=0.9, seed=i)\n",
    "    for i in range(N)\n",
    "]\n",
    "Output(Union(*fruits)).run(runner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "4 to 1 for Mango."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "```{note}\n",
    "We had to set `seed` to a different value in each `GenerateText` instance to disable local caching. Otherwise, we would get the same answer 5 times.\n",
    "```\n",
    "\n",
    "\n",
    "### Unknown sequence: Iterating via `ForEach`\n",
    "\n",
    "Assume we want to generate a list of reasons for why someone might fail an exam and then for each reason, we want a possible idea to fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+---------+--------------------------------------------------------------+\n",
       "| input   | output                                                       |\n",
       "+=========+==============================================================+\n",
       "| None    | ['Apple is considered a good fruit for several               |\n",
       "|         | reasons:\\n\\n1. Nutritional Value: Apples are rich in         |\n",
       "|         | essential nutrients like dietary fiber, vitamins             |\n",
       "|         | (particularly vitamin C), and minerals (such as potassium).  |\n",
       "|         | They are low in calories and fat, making them a healthy      |\n",
       "|         | snack option.\\n\\n2. Antioxidants: Apples contain             |\n",
       "|         | antioxidants, such as flavonoids and polyphenols, which help |\n",
       "|         | protect the body against oxidative stress and inflammation.  |\n",
       "|         | These antioxidants have been linked to various health        |\n",
       "|         | benefits...                                                  |\n",
       "+---------+--------------------------------------------------------------+\n",
       "Constants: None"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits = ExtractRegex(\n",
    "    GenerateText(\n",
    "        \"Generate a list of 5 fruits. Wrap each fruit with <item> and </item>.\"\n",
    "    ),\n",
    "    r\"<item>(.*?)<.?item>\"\n",
    ")\n",
    "\n",
    "fruit_blurbs = ForEach(\n",
    "    \"fruit\",\n",
    "    fruits,\n",
    "    GenerateText(Template(\"Why is {{fruit}} a good fruit?\")),\n",
    ")\n",
    "Output(fruit_blurbs).run(runner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Okay, that is more verbose than we want. What if we want to summarize it?\n",
    "\n",
    "We simply add on another “layer”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+---------+------------------------------------------------------------+\n",
       "| input   | output                                                     |\n",
       "+=========+============================================================+\n",
       "| None    | ['Apple: Nutritious, antioxidant-rich, fibrous, hydrating, |\n",
       "|         | versatile, long-lasting, tasty.', 'Oranges: Nutritious,    |\n",
       "|         | antioxidant-rich, hydrating, aids digestion, versatile,    |\n",
       "|         | refreshing.', 'Bananas: nutritious, energizing, aids       |\n",
       "|         | digestion, heart-healthy, mood-enhancing, versatile.',     |\n",
       "|         | 'Strawberries: low-cal, antioxidant-rich, high-fiber,      |\n",
       "|         | delicious, versatile fruit.', 'Grapes: nutritious,         |\n",
       "|         | hydrating, fibrous, heart-healthy, versatile, easy to      |\n",
       "|         | incorporate.']                                             |\n",
       "+---------+------------------------------------------------------------+\n",
       "Constants: None"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_fruit_blurbs = ForEach(\n",
    "    \"reason\",\n",
    "    fruit_blurbs,\n",
    "    GenerateText(\n",
    "        Template(\n",
    "            \"Rewrite the following text to have less than 10 words.\\n\\nInput: {{reason}}\\n\\nOutput: \"\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "Output(short_fruit_blurbs).run(runner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Nice! Alternatively, we could have tried changing the instructions to get this result directly, but LLMs often benefit from breaking tasks down into a series of smaller steps.\n",
    "\n",
    "## Using a custom operator\n",
    "\n",
    "Sometimes we would like to run a custom operation on the LLM output. The most flexibile solution would be to implement your own `Component` which we will cover in advanced concepts. In most cases, however, it is enough to simply use a `LambdaExtractor` with a user-defined function (UDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+---------+--------------------------------------------------+\n",
       "| input   | output                                           |\n",
       "+=========+==================================================+\n",
       "| None    | ['APPLE', 'banana', 'CHERRY', 'orange', 'GRAPE'] |\n",
       "+---------+--------------------------------------------------+\n",
       "Constants: None"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits_alt = ExtractRegex(\n",
    "    GenerateText(\n",
    "        \"Generate a list of 5 fruits in alternating caps. Wrap each fruit with <item> and </item>.\"\n",
    "    ),\n",
    "    r\"<item>(.*?)<.?item>\"\n",
    ")\n",
    "Output(fruits_alt).run(runner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Say we want to ensure now that each fruit name is in lowercase. To use the `LambdaExtractor`, we need to define a lambda function in a string (this is to make the whole prompt serializable). The lambda function takes one argument -- a single value passed on from the previous call and outputs a new value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+---------+--------------------------------------------------+\n",
       "| input   | output                                           |\n",
       "+=========+==================================================+\n",
       "| None    | ['apple', 'banana', 'cherry', 'orange', 'grape'] |\n",
       "+---------+--------------------------------------------------+\n",
       "Constants: None"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sammo.extractors import LambdaExtractor\n",
    "\n",
    "fruits_lowercased = LambdaExtractor(fruits_alt, \"lambda x: x.lower()\")\n",
    "Output(fruits_lowercased).run(runner)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
